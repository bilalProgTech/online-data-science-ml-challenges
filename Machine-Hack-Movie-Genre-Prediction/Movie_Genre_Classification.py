# -*- coding: utf-8 -*-
"""Logistic-Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/bilalProgTech/online-data-science-ml-challenges/blob/master/Machine-Hack-Movie-Genre-Prediction/Logistic-Regression.ipynb

# Problem Statement

Provided the entire script of the movie, can you classify it into the right genre.
Labeling text data can be hard. To use the available information to auto-create or predict the labels can be an interesting machine learning task. Using the power of Natural Language Processing (NLP) the unstructured text data can be leveraged to auto-generate the right classes for the test data in the future.

In order to accomplish this, we have scraped close to 2000 movie scripts and the respective genres.

As some of the scripts are huge, it would be interesting to figure out new ways of feature extraction and different NLP techniques.

In this hackathon participants are challenged to use the movie script to design a Natural language processing system that can help the customer classify it into the right genre in the coming future.
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import nltk
import re
import csv
import matplotlib.pyplot as plt
from tqdm import tqdm
# %matplotlib inline
pd.set_option('display.max_colwidth', 300)

train = pd.read_csv('Train.csv')
test = pd.read_csv('Test.csv')

train.head()

train.shape, test.shape

import os
data_folder = "C:\\Users\\hungu\\Documents\\MovieGenre\\MovieScriptsParticipantsData\\Scripts"
train['Script'] = [open(data_folder + os.sep + file, "r").read() for file in train['File_Name']]
test['Script'] = [open(data_folder + os.sep + file, "r").read() for file in test['File_Name']]

train.head()

print(train['Script'][3][:3000])

def clean_summary(text):
    text = re.sub("\'", "", text)
    text = re.sub("[^a-zA-Z]"," ",text)
    text = ' '.join(text.split())
    text = text.lower()
    text = ' '.join([w for w in text.split() if len(w)>3])
    return text

train['clean_script'] = train['Script'].apply(lambda x: clean_summary(x))
train.head(2)

from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))
def remove_stopwords(text):
    no_stopword_text = [w for w in text.split() if not w in stop_words]
    return ' '.join(no_stopword_text)
train['clean_script'] = train['clean_script'].apply(lambda x: remove_stopwords(x))
train.head(2)

train['Labels'].value_counts()

train.head()

test['clean_script'] = test['Script'].apply(lambda x: clean_summary(x))
test['clean_script'] = test['clean_script'].apply(lambda x: remove_stopwords(x))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

y = train['Labels']

x_train, x_val, ytrain, yval = train_test_split(train.clean_script.values, y, 
                                                random_state=2020, 
                                                test_size=0.1, shuffle=True)

def multiclass_logloss(actual, predicted, eps=1e-15):
    if len(actual.shape) == 1:
        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))
        for i, val in enumerate(actual):
            actual2[i, val] = 1
        actual = actual2

    clip = np.clip(predicted, eps, 1 - eps)
    rows = actual.shape[0]
    vsota = np.sum(actual * np.log(clip))
    return -1.0 / rows * vsota

tfidf_vectorizer = TfidfVectorizer(max_df=0.9, max_features=4000)
tfidf_vectorizer.fit(list(x_train) + list(x_val))
xtrain = tfidf_vectorizer.transform(x_train)
xval = tfidf_vectorizer.transform(x_val)

xtest = tfidf_vectorizer.transform(test.clean_script.values)

xtrain.shape, xval.shape

model = LogisticRegression()
model.fit(xtrain, ytrain)

pred_prob = model.predict_proba(xval)
print(multiclass_logloss(yval, pred_prob))

pred_test = model.predict_proba(xtest)

submission = pd.DataFrame(pred_test)
submission.insert(0, 'File_Name', test.File_Name)
submission.head()

submission.to_excel('Submission.xlsx', index=False)